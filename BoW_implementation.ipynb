{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Movie Sentiment Analasis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use the IMDB movie reviews dataset, provided on Kaggle (https://www.kaggle.com/c/word2vec-nlp-tutorial/data), to build a sentiment analysis model using NLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let us establish a baseline accuracy for our model using the tutorial provided by Kaggle alongside the dataset, found at https://www.kaggle.com/c/word2vec-nlp-tutorial/overview/description. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing this, we can work on increasing the efficiency of our model if we so desire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # to read the csv datasets and import them into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data\" # path to the data folder in your directory\n",
    "train_data = pd.read_csv(data_path + \"\\labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>\"3453_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It seems like more consideration has gone int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>\"5064_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"I don't believe they made this film. Complete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>\"10905_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Guy is a loser. Can't get girls, needs to bui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>\"10194_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This 30 minute documentary Buñuel made in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>\"8478_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I saw this movie as a child and it broke my h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "0       \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1       \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2       \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3       \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4       \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
       "...          ...        ...                                                ...\n",
       "24995   \"3453_3\"          0  \"It seems like more consideration has gone int...\n",
       "24996   \"5064_1\"          0  \"I don't believe they made this film. Complete...\n",
       "24997  \"10905_3\"          0  \"Guy is a loser. Can't get girls, needs to bui...\n",
       "24998  \"10194_3\"          0  \"This 30 minute documentary Buñuel made in the...\n",
       "24999   \"8478_8\"          1  \"I saw this movie as a child and it broke my h...\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup # to get rid of the HTML tags in the reviews\n",
    "import re # to remove punctuations and numericals from the review\n",
    "\n",
    "import nltk # to remove the stop words in our reviews\n",
    "nltk.download() \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_review(unclean_review):\n",
    "    \"\"\" \n",
    "    Function that takes a single unclean review from the original dataset\n",
    "    and returns a cleaned and preprocessed version of it. \n",
    "    Input: string: an uncleaned review from the dataset\n",
    "    Output: string: cleaned and preprocessed review\n",
    "    \"\"\"\n",
    "    # removes the HTML tags in the review\n",
    "    untagged_review = BeautifulSoup(unclean_review).get_text() \n",
    "    # removes everything not in A-Z or a-z and replaces it with a space\n",
    "    letter_only_review = re.sub(\"[^a-zA-Z]\", \" \", untagged_review) \n",
    "    # converting everything to lowercase\n",
    "    letter_only_review = letter_only_review.lower() \n",
    "    # converting everything to tokenized words\n",
    "    words_review = letter_only_review.split() \n",
    "    # converting to set for faster access\n",
    "    stop_words = set(stopwords.words(\"english\")) \n",
    "    # removing all the stop words in the review\n",
    "    words_review = [w for w in words_review if not w in stop_words] \n",
    "    words_review = \" \".join(words_review) \n",
    "    return words_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews done\n",
      "5000 reviews done\n",
      "10000 reviews done\n",
      "15000 reviews done\n",
      "20000 reviews done\n"
     ]
    }
   ],
   "source": [
    "total_reviews = len(train_data[\"review\"]) # total num of reviews in our training dataset\n",
    "cleaned_reviews = []\n",
    "for i in range(total_reviews):\n",
    "    clean_review = preprocess_review(train_data[\"review\"][i])\n",
    "    cleaned_reviews.append(clean_review)\n",
    "    if i % 5000 == 0:\n",
    "        print(\"{} reviews done\".format(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Feature Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will be using the Bag of Words model to create feature vectors for our reviews. Since the total vocabulary of our reviews is quite large, we will restrict ourselves to the 5000 most frequent words in our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # we will be using skleanr to automate most of our process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the CountVectorizer object with a max freq of 5000 words\n",
    "vectorizer = CountVectorizer(max_features = 5000)\n",
    "\n",
    "# learn the vocabulary and transform our reviews to their feature vectors\n",
    "train_features = vectorizer.fit_transform(cleaned_reviews)\n",
    "train_features = train_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will be training our model using Random Forest classifier with a a default value of 100. After gauging the accuracy, we can further finetune our model's hyperparameters to obtain greater accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# initializing our rf with a 400 trees\n",
    "forest = RandomForestClassifier(n_estimators = 400)\n",
    "\n",
    "# fit our forest to the training data\n",
    "forest = forest.fit(train_features, train_data[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews done\n",
      "5000 reviews done\n",
      "10000 reviews done\n",
      "15000 reviews done\n",
      "20000 reviews done\n"
     ]
    }
   ],
   "source": [
    "# import the test data to evaluate our model\n",
    "test_data = pd.read_csv(data_path + \"/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "# cleaning up the test data\n",
    "clean_test_reviews = []\n",
    "for i in range(len(test_data[\"review\"])):\n",
    "    clean_review = preprocess_review(test_data[\"review\"][i])\n",
    "    clean_test_reviews.append(clean_review)\n",
    "    if i % 5000 == 0:\n",
    "        print(\"{} reviews done\".format(i))\n",
    "\n",
    "test_features = vectorizer.transform(clean_test_reviews)\n",
    "test_features = test_features.toarray()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the rf to predict the results on the test data\n",
    "results = forest.predict(test_features)\n",
    "\n",
    "# create a Pandas DataFrame for our results\n",
    "output = pd.DataFrame(data={\"id\":test_data[\"id\"], \"sentiment\":results})\n",
    "\n",
    "# output the results in the specified format\n",
    "output.to_csv(\"BoW_model.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walmart",
   "language": "python",
   "name": "walmart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
